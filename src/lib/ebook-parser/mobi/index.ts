/**
 * https://wiki.mobileread.com/wiki/PDB
 * https://wiki.mobileread.com/wiki/MOBI
 */

import type { Book, BookContentEntry } from '@/types'
import { PDBHeader, PalmHeader, MobiHeader, EXTHHeader } from './types'
import { BookContentTypes } from '@/types'
import { readFileContent } from '@/utils'
import { parseHTML, parseXML } from '@/lib/ebook-parser/util'

class MobiFile {
    pdbHeader: PDBHeader
    palmHeader: PalmHeader
    header: MobiHeader
    exthHeader: EXTHHeader
    records: {
        offset: number
        attr: number
    }[] = []

    constructor() {
        this.pdbHeader = {} as PDBHeader
        this.palmHeader = {} as PalmHeader
        this.header = {} as MobiHeader
        this.exthHeader = {} as EXTHHeader
    }
}

let mobi: MobiFile
const decoder = new TextDecoder('utf-8')
let offset = 0
let dataView: DataView
let fileTitle: string
let images: string[] = []

function jumpTo(_offset: number) {
    offset = _offset
}

function readString(length: number) {
    return decoder.decode(dataView.buffer.slice(offset, (offset += length)))
}

function peakString(length: number) {
    return decoder.decode(dataView.buffer.slice(offset, offset + length))
}

function readBytes(num: number) {
    let result
    if (num === 1) {
        result = dataView.getUint8(offset)
    } else if (num === 2) {
        result = dataView.getUint16(offset)
    } else if (num === 4) {
        result = dataView.getUint32(offset)
    } else if (num === 8) {
        result = dataView.getBigUint64(offset)
    }

    skip(num)
    return result as number
}

function skip(num: number) {
    offset += num
}

/**
 * https://wiki.mobileread.com/wiki/PalmDOC#LZ77_compression
 * generated by ChatGPT, modified by me~
 * @param compressedData
 */
function lz77Decompress(compressedData: Uint8Array): Uint8Array {
    let decompressedData: number[] = []
    let i = 0
    while (i < compressedData.length) {
        const c = compressedData[i]

        if (c === 0x00 || (c >= 0x09 && c <= 0x7f)) {
            // "1 literal"
            decompressedData.push(c)
            i++
        } else if (c >= 0x01 && c <= 0x08) {
            // "literals"
            const count = c
            for (let j = 0; j < count; j++) {
                decompressedData.push(compressedData[i + j + 1])
            }
            i += count + 1
        } else if (c >= 0x80 && c <= 0xbf) {
            // "length, distance" pair
            const byte1 = c
            const byte2 = compressedData[i + 1]
            const distance = (((byte1 & 0x3f) << 8) | byte2) >> 3
            const length = (byte2 & 0x7) + 3
            const start = decompressedData.length - distance
            for (let j = 0; j < length; j++) {
                decompressedData.push(decompressedData[start + j])
            }
            i += 2
        } else {
            // "byte pair"
            const byte2 = c ^ 0x80
            decompressedData.push(0x20, byte2)
            i++
        }
    }
    return new Uint8Array(decompressedData)
}

function parsePDBHeader() {
    const { pdbHeader } = mobi
    pdbHeader.name = readString(32)
    pdbHeader.attributes = readBytes(2)
    pdbHeader.version = readBytes(2)
    pdbHeader.createTime = readBytes(4)
    pdbHeader.modificationTime = readBytes(4)
    pdbHeader.lastBackupTime = readBytes(4)
    pdbHeader.modificationNumber = readBytes(4)
    pdbHeader.appInfoId = readBytes(4)
    pdbHeader.sortInfoId = readBytes(4)
    pdbHeader.type = readString(4)
    pdbHeader.creator = readString(4)
    pdbHeader.uniqueIDSeed = readBytes(4)
    pdbHeader.nextRecordListId = readBytes(4)
    pdbHeader.numberOfRecords = readBytes(2)
}

function parseMobiRecords() {
    let currentRecordIndex = 0
    while (currentRecordIndex < mobi.pdbHeader.numberOfRecords) {
        mobi.records.push({
            offset: readBytes(4),
            attr: readBytes(4),
        })
        currentRecordIndex++
    }
}

function parsePalDocHeader() {
    const { palmHeader } = mobi
    palmHeader.compression = readBytes(2)
    palmHeader.unused = readBytes(2)
    palmHeader.textLength = readBytes(4)
    palmHeader.recordCount = readBytes(2)
    palmHeader.recordSize = readBytes(2)
    palmHeader.currentPosition = readBytes(4)
}

function parseMobiHeader() {
    const { header } = mobi
    const _offset = offset
    header.identifier = readString(4)
    header.headerLength = readBytes(4)
    header.mobiType = readBytes(4)
    header.textEncoding = readBytes(4)
    header.uniqueID = readBytes(4)
    header.fileVersion = readBytes(4)
    header.ortographicIndex = readBytes(4)
    header.inflectionIndex = readBytes(4)
    header.indexNames = readBytes(4)
    header.indexKeys = readBytes(4)
    header.extraIndex0 = readBytes(4)
    header.extraIndex1 = readBytes(4)
    header.extraIndex2 = readBytes(4)
    header.extraIndex3 = readBytes(4)
    header.extraIndex4 = readBytes(4)
    header.extraIndex5 = readBytes(4)
    header.firstNoneBookIndex = readBytes(4)
    header.fullNameOffset = readBytes(4)
    header.fullNameLength = readBytes(4)
    header.locale = readBytes(4)
    header.inputLanguage = readBytes(4)
    header.outputLanguage = readBytes(4)
    header.miniVersion = readBytes(4)
    header.firstImageIndex = readBytes(4)
    header.huffmanRecordOffset = readBytes(4)
    header.huffmanRecordCount = readBytes(4)
    header.huffmanTableOffset = readBytes(4)
    header.huffmanTableLength = readBytes(4)
    header.exthFlags = readBytes(4)

    skip(32)
    skip(4)
    header.drmOffset = readBytes(4)
    header.drmCount = readBytes(4)
    header.drmSize = readBytes(4)
    header.drmFlags = readBytes(4)
    skip(8)
    header.firstContentRecordNumber = readBytes(2)
    header.lastContentRecordNumber = readBytes(2)
    skip(4)
    header.fcisRecordNumber = readBytes(4)
    header.unknownFcisRecordCount = readBytes(4)
    header.flisRecordNumber = readBytes(4)
    header.unknownFlisRecordCount = readBytes(4)
    skip(8)
    skip(4)
    header.firstCompilationDataSectionCount = readBytes(4)
    header.numberOfCompilationDataSections = readBytes(4)
    skip(4)
    console.log(new Uint8Array(dataView.buffer.slice(offset, offset + 4)))
    header.extraRecordDataFlags = readBytes(4)
    header.indxRecordOffset = readBytes(4)
    jumpTo(_offset + header.headerLength)
}

const exthHeaderMap: Record<string, [string, 'number' | 'string']> = {
    1: ['drm_server_id', 'string'],
    2: ['drm_commerce_id', 'string'],
    3: ['drm_ebookbase_book_id', 'string'],
    100: ['author', 'string'],
    101: ['publisher', 'string'],
    102: ['imprint', 'string'],
    103: ['description', 'string'],
    104: ['isbn', 'string'],
    105: ['subject', 'string'],
    106: ['publishingdate', 'string'],
    107: ['review', 'string'],
    108: ['contributor', 'string'],
    109: ['rights', 'string'],
    110: ['subjectcode', 'string'],
    111: ['type', 'string'],
    112: ['source', 'string'],
    113: ['asin', 'string'],
    114: ['versionnumber', 'string'],
    115: ['sample', 'string'],
    116: ['startreading', 'number'],
    117: ['adult', 'string'],
    118: ['retail price', 'string'],
    // ...
    201: ['coveroffset', 'number'],
    202: ['thumboffset', 'number'],
}

// skip
function parseExthHeader() {
    if (peakString(4) !== 'EXTH') {
        return
    }

    const _offset = offset
    readString(4)

    const headerLength = readBytes(4)
    let count = readBytes(4)

    const { exthHeader } = mobi

    while (count--) {
        const type = readBytes(4)
        const recordLength = readBytes(4)
        const match = exthHeaderMap[type]

        if (match) {
            if (match[1] === 'string') {
                exthHeader[match[0]] = readString(recordLength - 8)
            } else {
                exthHeader[match[0]] = readBytes(recordLength - 8)
            }
        } else {
            readString(recordLength - 8)
        }
    }

    jumpTo(_offset + headerLength)
}

const FLAG_MULTIBYTE_OVERLAP = 0x0001

function readTrailingEntry(bytes: Uint8Array, flags: number) {
    let entry = {}

    if (flags & FLAG_MULTIBYTE_OVERLAP) {
        // Read multibyte character overlap entry
        entry.type = 'multibyteOverlap'
        entry.data = bytes.slice(0, 4)
        entry.sizeAndFlags = bytes.slice(4, 5)
        // bytes = bytes.slice(0, bytes.length - 5)
    } else {
        // Other trailing entries are currently unknown
        entry.type = 'unknown'
        entry.data = bytes
        entry.sizeAndFlags = null
        bytes = []
    }

    return { entry, remainingBytes: bytes }
}

function decodeVariableWidthInteger(bytes) {
    let value = 0
    let shift = 0
    console.log(bytes)

    for (let i = bytes.length - 1; i >= 0; i--) {
        const byte = bytes[i]
        value += (byte & 0x7f) << shift
        shift += 7
        if ((byte & 0x80) === 0) {
            break
        }
    }

    return value
}

function get_record_extrasize(data, flags) {
    if (flags & FLAG_MULTIBYTE_OVERLAP) {
        let offset = data.length - 1
        let size = 0
        let shift = 0
        while (true) {
            const byte = data[offset]
            size |= (byte & 0x7f) << shift
            shift += 7
            if ((byte & 0x80) === 0) {
                break
            }
            offset--
        }
        // return the overlapping bytes
        const overlapSize = size & 0x03 // bits 1-2 encode N
        const overlapOffset = data.length - overlapSize - size - 1
        return overlapSize
    } else {
        return 0
    }
    // var pos = data.length - 1
    // var extra = 0
    // for (var i = 15; i > 0; i--) {
    //     if (flags & (1 << i)) {
    //         var res = buffer_get_varlen(data, pos)
    //         var size = res[0]
    //         var l = res[1]
    //         pos = res[2]
    //         pos -= size - l
    //         extra += size
    //     }
    // }
    // if (flags & 1) {
    //     var a = data[pos]
    //     extra += (a & 0x3) + 1
    // }
    // return extra
}

// data should be uint8array
function buffer_get_varlen(data, pos) {
    var l = 0
    var size = 0
    var byte_count = 0
    var mask = 0x7f
    var stop_flag = 0x80
    var shift = 0
    for (var i = 0; ; i++) {
        var byte = data[pos]
        size |= (byte & mask) << shift
        shift += 7
        l += 1
        byte_count += 1
        pos -= 1

        var to_stop = byte & stop_flag
        if (byte_count >= 4 || to_stop > 0) {
            break
        }
    }
    return [size, l, pos]
}

function parseRecords() {
    const { header, palmHeader, records } = mobi
    const text: Uint8Array[] = []
    let totalLength = 0
    for (
        let i = header.firstContentRecordNumber;
        i <= palmHeader.recordCount;
        i++
    ) {
        const begin = records[i].offset
        const end = records[i + 1].offset
        let data = new Uint8Array(dataView.buffer.slice(begin, end))

        // const { remainingBytes } = readTrailingEntry(
        //     data,
        //     header.extraRecordDataFlags
        // )
        const extra = get_record_extrasize(data, header.extraRecordDataFlags)
        console.log('extra', extra)
        data = new Uint8Array(dataView.buffer.slice(begin, end - extra))
        // console.log(
        //     'trailing entry',
        //     remainingBytes.length,
        //     get_record_extrasize(data, header.extraRecordDataFlags)
        // )

        if (palmHeader.compression === 2) {
            let result = lz77Decompress(data)
            totalLength += result.length
            text.push(result)
        } else {
            totalLength += data.length
            text.push(data)
        }
    }

    if (header.firstImageIndex && header.lastContentRecordNumber) {
        for (
            let i = header.firstImageIndex;
            i <= header.lastContentRecordNumber;
            i++
        ) {
            const begin = records[i].offset
            const end = records[i + 1].offset
            const data = new Uint8Array(dataView.buffer.slice(begin, end))
            images.push(
                URL.createObjectURL(new Blob([data], { type: 'image/png' }))
            )
        }
    }

    const combinedTextArray = new Uint8Array(totalLength)
    let index = 0
    text.forEach((fragment) => {
        // console.log(new TextDecoder('utf-8').decode(fragment))
        combinedTextArray.set(fragment, index)
        index += fragment.length
    })
    const finalText = new TextDecoder('utf-8').decode(combinedTextArray)
    return finalText
}

function getRemainderOfRecord0() {
    const title = readString(mobi.records[1].offset - offset)

    if (title) {
        fileTitle = title
    }
}

function parseMobiFile() {
    parsePDBHeader()
    parseMobiRecords()
    jumpTo(mobi.records[0].offset)
    parsePalDocHeader()
    parseMobiHeader()
    parseExthHeader()
    getRemainderOfRecord0()
    console.log(mobi)
    return parseRecords()

    // console.log('mobi file structure', mobi)
}

function fixImage(text: string) {
    const doc = parseHTML(text)
    console.log(doc)
    const imgs = doc.querySelectorAll('img') || []

    for (let img of imgs) {
        const imgIndex = img.getAttribute('recindex')

        if (imgIndex) {
            img.src = images[Number.parseInt(imgIndex, 10) - 1]
        }
    }

    return doc.body.innerHTML as string
}

export async function parse(rawContent: File): Promise<Book> {
    const result = await readFileContent(rawContent)
    let entries: BookContentEntry[]
    images = []

    if (result.isOK) {
        mobi = new MobiFile()
        dataView = new DataView(result.content as ArrayBuffer)
        const content = fixImage(parseMobiFile())

        entries = [
            {
                type: BookContentTypes.html,
                content,
            },
        ]
    } else {
        entries = []
    }

    return {
        isLoaded: true,
        entries,
    }
}
